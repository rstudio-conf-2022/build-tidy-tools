---
title: "üì¶ <br>Building tidy tools"
subtitle: "Day 1 Session 3: Unit tests"
author: "Emma Rand and Ian Lyttle"
date: "<br>üîó [rstd.io/btt](https://rstd.io/btt)"
format:
  revealjs: 
    theme: [simple, emma.scss]
    slide-number: true
    chalkboard: true
    preview-links: auto
    footer: <https://rstd.io/btt>
    margin: 0.07
    code-link: true
    code-line-numbers: false
    height: 900
    width: 1600
execute:
  echo: true
  eval: false
bibliography: references.bib
---

# ‚òëÔ∏è Unit Testing

## Learning Objectives

At the end of this section you will be able to:

::: small
-   understand the rationale for automating tests
-   describe the organisation of the testing infrastructure and file contents for the **`testthat`** [@testthat] workflow
-   set up a package to use **`testthat`**
-   create a test and use some common 'expectations'
-   run all the tests in a file and in a package
-   determine the test coverage in a package
:::

# Why test?

## Why test?

-   To make sure our code works

-   To make sure our code keeps working after we add features

## For example

When we run:

```{r}
italy <- uss_make_matches(engsoccerdata::italy,
                          "Italy")
spain <- uss_make_matches(engsoccerdata::spain,
                          "Spain")
```

. . .

The objects `italy` and `spain` should be:

-   tibbles
-   have columns: "country", "tier", "season", "date", "home", "visitor", "goals_home" and "goals_visitor"

\

So we might...

## Check interactively

Try these:

::: columns
::: {.column width="80%"}
::: extrasmall
```{r}
class(italy)
```

``` default
"tbl_df"     "tbl"        "data.frame"
```

```{r}
class(spain)
```

``` default
"tbl_df"     "tbl"        "data.frame" 
```

```{r}
names(italy)
```

``` default
country"       "tier"          "season"        "date"         
"home"          "visitor"       "goals_home"    "goals_visitor" 
```

```{r}
names(spain)
```

``` default
country"       "tier"          "season"        "date"         
"home"          "visitor"       "goals_home"    "goals_visitor"
```
:::
:::

::: {.column width="20%"}
üéâ

\

ü•≥

\

üéà

\

üéá
:::
:::

## Interactive testing ...

...is informal testing:

-   wrote `uss_make_matches()`
-   loaded package with `devtools::load_all()`
-   ran `uss_make_matches()` interactively
-   edited `uss_make_matches()` if needed
-   loaded package with `devtools::load_all()`
-   ran `uss_make_matches()` interactively

## Informal test workflow

```{mermaid}
%%| evaluate:: true
%%| fig-width: 10
%%| fig-height: 5
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#f3f3f3',  'lineColor':'#EE9AD9'}}}%%

  flowchart LR
      id1("Reload code: \n load_all()") --> 
      id2("Explore in \n console") --> 
      id3("Modify \n code")
      id3 --> id1
      style id1 id2 id3 stroke:#3F3F3F,stroke-width:2px

```

# Why automate testing?

## Why automate testing?

Problem: you forget all the interactive testing you've done

. . .

Solution: have a system to store and re-run the tests!

## Why automate testing?

1.  Fewer bugs: you are explicit about behaviour of functions.

2.  Encourages good code design. If it is hard to write unit tests your function may need refactoring

3.  Opportunity for test-driven development

4.  Robustness

. . .

Read more about testing in the recently updated chapter in R Packages [@wickham2020a]

## Automated test workflow

```{mermaid}
%%| evaluate:: true
%%| fig-width: 10
%%| fig-height: 5
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#f3f3f3',  'lineColor':'#EE9AD9'}}}%%

  flowchart LR
      id1("Reload code: \n load_all()") --> 
      id2("Run automated tests: \n test() or test_file()") --> 
      id3("Modify \n code")
      id3 --> id1
      style id1 id2 id3 stroke:#3F3F3F,stroke-width:2px

```

# Infrastructure and organisation

## Organisation: files

::: columns
::: {.column width="40%"}
::: small
``` default
.
‚îú‚îÄ‚îÄ CITATION.cff
‚îú‚îÄ‚îÄ DESCRIPTION
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ LICENSE.md
‚îú‚îÄ‚îÄ man
‚îÇ   ‚îî‚îÄ‚îÄ matches.Rd
‚îú‚îÄ‚îÄ NAMESPACE
‚îú‚îÄ‚îÄ R
‚îÇ   ‚îî‚îÄ‚îÄ matches.R
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ tests
‚îÇ   ‚îú‚îÄ‚îÄ testthat
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test-matches.R
‚îÇ   ‚îî‚îÄ‚îÄ testthat.R
‚îî‚îÄ‚îÄ ussie.Rproj
```
:::
:::

::: {.column width="60%"}
-   tests files are in: `tests/testthat/`
-   test files are named `test-xxxx.R`
-   `tests/testthat.R`: runs the tests when `devtools::check()` is called
:::
:::

## Organisation within files

-   any test file `test-xxxx.R` contains several tests. Might be:
    -   all the tests for a simple function
    -   all the tests for one part of a complex function
    -   all the tests for the same functionality in multiple functions

## Organisation within files

-   a test groups several 'expectations'. An expectation:
    -   has the form: `expect_zzzz(actual_result, expectation)`
    -   if `actual_result` == `expectation` no error
    -   if `actual_result` != `expectation` Error

# Workflow

## Workflow

1.  Set up your package to use **`testthat`**: `usethis::use_testthat(3)` ONCE

. . .

2.  Make a test: `usethis::use_test()`

. . .

3.  Run a set of tests: `testthat::test_file()`

. . .

4.  Run the entire testing suite: `devtools::test()` and `devtools::check()`

# Set up

## Set up

To set up your package to use **`testthat`**: `usethis::use_testthat(3)` which:

-   makes `tests/testthat/`: this is where the test files live

-   edits `DESCRIPTION`:

    -   Adds `Suggests:   testthat (>= 3.0.0)`
    -   Adds `Config/testthat/edition: 3`

-   makes `tests/testthat.R`: this runs the test when you do `devtools:check()` DO NOT EDIT

## Set up

üé¨ Set up your package to use **`testthat`**:

```{r}
usethis::use_testthat(3)
```

\

. . .

3 means **`testthat`** edition 3 (**`testthat 3e`**)

As well as installing that version of the package, you have to explicitly opt in the edition behaviours.

## 

::: small
``` default
‚úî Adding 'testthat' to Suggests field in DESCRIPTION
‚úî Setting Config/testthat/edition field in DESCRIPTION to '3'
‚úî Creating 'tests/testthat/'
‚úî Writing 'tests/testthat.R'
‚Ä¢ Call `use_test()` to initialize a basic test file and open it for editing.
```
:::

# Expectations

## Expectations

Before we try to make a test, let's look at some of the `expect_zzzz()` functions we have available to us.

. . .

Form: `expect_zzzz(actual_result, expectation)`

. . .

-   the `expectation` is what you expect
-   the `actual_result` is what you are comparing to the expectation
-   some `expect_zzzz()` have additional arguments

## For example

```{r}
#| eval: true
#| error: true
# to try out testhtat interactively we load 
# and request edition 3
# but, you do *not* do that in a package.
library(testthat)
local_edition(3)

# when the actual result is 42
result <- 42

# and we expect the result to be 42: no error
expect_identical(result, 42)
```

## and

```{r}
#| eval: true
#| error: true
# when the actual result is "a"
result <- "a"

# and we expect the result to be "a": no error
expect_identical(result, "a")
```

## But

```{r}
#| eval: true
#| error: true
# when the actual result is 45
result <- 45

# and we expect the result to be 42: Error
expect_identical(result, 42)
```

## and

```{r}
#| eval: true
#| error: true
# when the actual result is "bob"
result <- "bob"

# and we expect the result to be "a": Error
expect_identical(result, "A")
```

## Some common expectations

Some types of `expect_zzzz()`

-   Testing for identity: `expect_identical()`
-   Testing for equality with wiggle room: `expect_equal()`
-   Testing something is TRUE: `expect_true()`
-   Testing whether objects have names: `expect_named()`
-   Testing errors: `expect_error()`

::: aside
All expectations are in **`testthat`** [documentation](https://testthat.r-lib.org/reference/index.html)
:::

## Equality with wiggle room

```{r}
#| eval: true
#| error: true
# when the actual result is 42
result <- 42

# and we expect the result to be 42: no error
expect_equal(result, 42)
```

```{r}
#| eval: true
#| error: true
# and when the actual result is 42.0000001
result <- 42.0000001

# and we expect the result to be 42: we still do 
# not have an error because expect_equal() 
# has some tolerance
expect_equal(result, 42)
```

## Equality with wiggle room

```{r}
#| eval: true
#| error: true
# but when the actual result is 42.1
result <- 42.1

# and we expect the result to be 42: error because
# 0.1 is bigger than the default tolerance
expect_equal(result, 42)
```

::: aside
Default tolerance is relative to the values calculated by `waldo::compare()` using the algorithm in `all.equal()`
:::

## Equality with wiggle room

We can set the wiggle room:

```{r}
#| eval: true
#| error: true
# but when the actual result is 42.1
result <- 42.1

# and we expect the result to be 42: no error if we
# provide a tolerance
expect_equal(result, 42, tolerance = 0.1)
```

## Testing something is TRUE

```{r}
#| eval: true
#| error: true

expect_true("a" == "a")
```

## Testing whether objects have names

```{r}
#| eval: true
#| error: true
# vector of named values
x <- c(a = 1, b = 2, c = 3)

# test whether x has names: no error
expect_named(x)
# test if the names are "a", "b", "c": no error
expect_named(x, c("a", "b", "c"))
```

# Making a test

## Make a test

You can create and open (or just open) a test file for `blah.R` with `use_test("blah")`.

. . .

üé¨ Create a test file for `matches.R` . . .

```{r}
usethis::use_test("matches")
```

. . .

``` default
‚úî Writing 'tests/testthat/test-matches.R'
‚Ä¢ Modify 'tests/testthat/test-matches.R'
```

::: aside
If matches.R is active in the editor, then `usethis::use_test()` is enough
:::

## Test file structure

For example:

``` default
test_that("multiplication works", {
  expect_equal(2 * 2, 4)
})
```

. . .

Generally:

``` default
test_that("some thing in the function works", {
  expect_zzzz()
  expect_zzzz()
  ...
})
```

## Make a test

We will add three expectations:

-   test that the output of `uss_make_matches()` is a tibble with `expect_true()`

. . .

-   test that the output of `uss_make_matches()` has columns with the right names with `expect_named()`

. . .

-   test that the country column of the `uss_make_matches()` output is correct with `expect_identical()`

. . .

We will do them one at a time so you can practice the workflow.

## Edit `test-matches.R`

üé¨ Add a test to check the output of `uss_make_matches()` is a tibble with `expect_true()`:

. . .

::: small
```{r}
test_that("uss_make_matches works", {

  # use the function
  italy <- uss_make_matches(engsoccerdata::italy, "Italy")

  expect_true(tibble::is_tibble(italy))
})

```
:::

. . .

We use `uss_make_matches()` and examine the output with an expectation.

# Running a test

## Running a test

üé¨ Run the test with `testthat::test_file()`

```{r}
testthat::test_file("tests/testthat/test-matches.R")
```

You can also use the "Runs Tests" button

. . .

``` default
‚ïê‚ïê Testing test-matches.R ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ] Done!
```

ü•≥

## `devtools::test()`

üé¨ Run all the tests with `devtools::test()`

```{r}
devtools::test()
```

. . .

::: small
``` default
‚Ñπ Loading ussie
‚Ñπ Testing ussie
‚úî | F W S  OK | Context
‚úî |         1 | matches [0.4s]                                   

‚ïê‚ïê Results ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Duration: 0.5 s

[ FAIL 0 | WARN 0 | SKIP 0 | PASS 1 ]

üêù Your tests are the bee's knees üêù
```
:::

## Add an expectation

Now you will test the output of `uss_make_matches()` to make sure it has columns with the right names `expect_named()`

. . .

we expect the names to be:

::: small
"country", "tier", "season", "date", "home", "visitor", "goals_home", "goals_visitor"
:::

. . .

üé¨ Use `expect_named()` in `test-matches.R` to check the column names of `italy`

## Answer

::: small
```{r}
test_that("uss_make_matches works", {

  # use the function
  italy <- uss_make_matches(engsoccerdata::italy, "Italy")

  expect_true(tibble::is_tibble(italy))
  expect_named(
    italy,
    c("country", "tier", "season", "date", "home", "visitor",
      "goals_home", "goals_visitor")
  )
})
```
:::

## Run the edited test

üé¨ Run the edited test file

. . .

```{r}
testthat::test_file("tests/testthat/test-matches.R")
```

Or the "Runs Tests" button

``` default
‚ïê‚ïê Testing test-matches.R ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ] Done!
```

## 

```{r}
devtools::test()
```

::: small
``` default
‚Ñπ Loading ussie
‚Ñπ Testing ussie
‚úî | F W S  OK | Context
‚úî |         2 | matches [0.2s]                                                 

‚ïê‚ïê Results ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Duration: 0.2 s

[ FAIL 0 | WARN 0 | SKIP 0 | PASS 2 ]   
```
:::

ü•≥

## Add the last expectation

Now check that the country column of the `uss_make_matches()` output is correct with `expect_identical()`

. . .

üé¨ Use `expect_identical()` in `test-matches.R` to compare the values in `italy$country` to "italy"

. . .

üé¨ Run the tests

## My answer

::: small
```{r}
test_that("uss_make_matches works", {

  # use the function
  italy <- uss_make_matches(engsoccerdata::italy, "Italy")

  expect_true(tibble::is_tibble(italy))
  expect_named(
    italy,
    c("country", "tier", "season", "date", "home", "visitor",
      "goals_home", "goals_visitor")
  )
  expect_identical(unique(italy$country), "Italy")
})
```
:::

## Extra: find a bug, add a test

Running a practice session for this course, we found a bug:

::: small
```{r}
test_that("uss_make_matches works", {

  # use the function
  italy <- uss_make_matches(engsoccerdata::italy, "Italy")

  expect_true(tibble::is_tibble(italy))
  expect_named(
    italy,
    c("country", "tier", "season", "date", "home", "visitor",
      "goals_home", "goals_visitor")
  )
  expect_identical(unique(italy$country), "Italy")
  
  # when you find a bug, add a test: üëã from Ian
  expect_s3_class(italy$tier, "factor")
})
```
:::

# Test coverage

## Test coverage

Test coverage is the percentage of package code run when the test suite is run.

-   provided by **`covr`** [@covr] package
-   higher is better
-   100% is notional goal but rarely achieved

## Test coverage

There are two functions you might use interactively:

-   coverage on the active file: `devtools::test_coverage_active_file()`

-   coverage on the whole package:`devtools::test_coverage()`

## Coverage in active file

üé¨ Make sure `matches.R` is active in the editor and do:

```{r}
devtools::test_coverage_active_file()
```

. . .

![](images/test-covr-active-file.png){width="500"}

## Coverage in package

üé¨ Check the coverage over the whole package:

```{r}
devtools::test_coverage()
```

. . .

![](images/test-covr-pkg.png){width="500"}

# ‚òëÔ∏è Woo hoo ‚òëÔ∏è<BR> You wrote a unit test!

## Commit and push

Now would be a good time to commit your changes and push them to GitHub

![Jason Long, CC BY 3.0 \<https://creativecommons.org/licenses/by/3.0\>, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/3/3f/Git_icon.svg){fig-alt="Git icon" width="300"} ![GitHub, MIT \<http://opensource.org/licenses/mit-license.php\>, via Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg){fig-alt="GitHub icon" width="300"}

## Summary

::: small
-   Automated testing means you can systematically check your code still works when adding features
-   **`testthat`** *"tries to make testing as fun as possible"*
-   Organisation: test files
    -   live in: `tests/testthat/`
    -   are named: `test-xxxx.R`
    -   contain: `test_that("something works", { *expectations* })`
    -   `tests/testthat.R`: runs the tests and should not (normally) be edited
:::

## Summary

::: small
-   Expectations have the form `expect_zzzz(actual_result, expectation)`
-   Workflow
    -   `usethis::use_testthat(3)` sets up your package to use **`testthat`**
    -   `usethis::use_test(xxxx)` creates `test-xxxx.R`
    -   `testthat::test_file()` runs the tests in a test file
    -   `devtools::test()` runs the tests in all the test files
-   Test coverage can be determined
    -   on the active file with `devtools::test_coverage_active_file()`
    -   on the whole package:`devtools::test_coverage()`
:::

## References {.extrasmall}
